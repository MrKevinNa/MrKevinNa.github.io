---
title: "JavaScript 우회하기"
author: "Dr.Kevin"
date: "1/28/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, out.width = '750px', dpi = 300)
```

왜 **JavaScript**를 알아야 할까요? 웹크롤링을 하다 보면 분명히 응답 상태코드가 `200`으로 정상인데 찾는 `HTML element`가 없는 경우가 매우 많습니다. 이런 경우, **JavaScript**를 의심해볼 필요가 있습니다.

`HTML`을 보면 중간에 `<script>`라는 `tag`가 있고, 그 아래로 프로그래밍 코드 뭉치가 보이는 경우가 흔히 있습니다. 만약 우리가 찾는 `HTML element`가 `<script>`에 영향을 받으면 관련 `HTML element`가 뒤늦게 불려오기 때문에 비록 **HTML Response**이 정상이어도 찾는 `HTML element`가 응답 객체에 포함되지 않는 것입니다. (혹시 제가 잘못 기술한 부분이 있다면 피드백을 부탁 드립니다!)

위 문제를 해결하는 방법은 크게 2가지가 있습니다.  

1. 크롬의 사용자도구에서 '네트워크' 탭에서 새로고침(F5)하여 원하는 데이터가 화면에 렌더링되는 시점을 포착하는 방식으로 관련 항목을 찾는다.  

1. RSelenium을 사용하여 원하는 코드를 얻는다.  

두 번째 방법은 속도가 느리다는 단점도 있지만 이 포스팅 다음에 소개해드릴 예정이므로, 이번 포스팅에서는 첫 번째 방법을 사용하여 원하는 데이터를 수집해 보겠습니다.

```{r message=FALSE}
# 필요 패키지를 불러옵니다.
library(httr)
library(rvest)
library(dplyr)
library(stringr)
```

이번 예제에서는 **2017년 프로야구 타자 스탯**을 수집해보도록 하겠습니다. [KBReport](http://www.kbreport.com/main)로 이동하여 화면 상단에 여러 메뉴가 있습니다. 여기에서 `선수기록`을 클릭하면 선수 스탯이 테이블 형태로 출력됩니다. 데이터 조회 조건으로 아래와 같이 변경하였습니다.  

  - 팀 : "팀-전체"  
  - 포지션 : "포지션-전체"  
  - 시즌범위 : "시즌 시작-2017"  
  - TO : "종료 시즌-2017"  
  - 정규/포스트 시즌 구분 : "정규시즌"  
  - 분류1 : "분류-선택안함"  
  - 타석수 : "타석수-전체"  

위와 같이 설정한 후 우측에 있는 `결과` 버튼을 클릭하면 아래에 테이블 형태로 데이터가 출력됩니다. `URL`이 바뀌었으므로 바뀐 `URL`을 `GET()` 함수에 할당하여 실행시키면 정상 응답을 받을 수 있지만 찾고자 하는 `HTML element`는 없습니다. 

다시 크롬으로 돌아가서 출력된 상태에서 크롬 개발자도구를 열고 **Network** 탭으로 이동한 다음 새로고침(F5)을 누릅니다. 매우 많은 항목들이 주르륵하고 생기는데, 이 때 주목해야 할 것은 개발자도구 위에서 세 번째 줄에 있는 메뉴입니다. 아마도 **All**이 선택되어 있을 것입니다. 이것을 **XHR**로 변경하면 항목이 크게 줄어듭니다.

**XHR**은 **XML Http Request**의 머릿글자로 **AJAX** 요청을 생성하는 **JavaScript API**라고 합니다^[XHR에 대한 자세한 내용은 [여기](https://developer.mozilla.org/ko/docs/Glossary/XHR_(XMLHttpRequest))를 확인해보시기 바랍니다]. 그리고 **AJAX**는 **Asynchronos Javascript And XML**의 머릿글자로 JavaScript와 XML을 의미한다고 합니다. 단순하게 요약하자면, **JavaScript**를 통해서 웹서버로부터 **XML** 데이터를 요청하는 것입니다^[AJAX에 대한 자세한 내용은 [여기](http://wherethelightis.tistory.com/14)를 참조하시기 바랍니다].

저도 잘 모르는 걸 설명하려니 어렵네요. 아무튼 다시 크롬 개발자도구의 **Network** 탭으로 돌아가서, 세 번째 줄 메뉴에 있는 **XHR**로 이동하면 첫 번째 그림처럼 보일 것입니다.

![](https://raw.githubusercontent.com/MrKevinNa/MrKevinNa.github.io/master/images/2018-01-19-R-Crawler-2_files/Chrome%20Developer%20Tools%20Network%206.png)

이제 새로고침을 하면 두 번째 그림처럼 몇 가지 항목이 생성되는데 중간에 **AJAX**가 있고 **POST** 방식으로 요청한다는 것을 확인할 수 있습니다.

![](https://raw.githubusercontent.com/MrKevinNa/MrKevinNa.github.io/master/images/2018-01-19-R-Crawler-2_files/Chrome%20Developer%20Tools%20Network%207.png)

그리고 **AJAX**를 선택하면 오른쪽에서 Request와 Response에 관한 세부사항을 확인할 수 있는데요. **General**에서 **Request URL**을 복사하여 `POST()` 함수의 `url`인자에 할당합니다.

![](https://raw.githubusercontent.com/MrKevinNa/MrKevinNa.github.io/master/images/2018-01-19-R-Crawler-2_files/Chrome%20Developer%20Tools%20Network%209.png)

그리고 나서 **Form Data**가 보일 때까지 화면을 아래로 내린 다음 인자명과 인자값을 복사해서 `POST()` 함수의 `body` 인자에 리스트 형태로 할당해주면 됩니다.

![](https://raw.githubusercontent.com/MrKevinNa/MrKevinNa.github.io/master/images/2018-01-19-R-Crawler-2_files/Chrome%20Developer%20Tools%20Network%208.png)

```{r}
# HTML 요청 합니다.
resp <- POST(url = "http://www.kbreport.com/leader/list/ajax",
             encode = "form",
             body = list(
               rows = 20,
               order = "oWAR",
               orderType = "DESC",
               year_from = 2017,
               year_to = 2017,
               gameType = "R",
               page = 1)
             )

# 응답 상태코드를 확인합니다.
status_code(resp)
```

응답 상태코드가 `200`으로 정상입니다. 이제 크롬 개발자도구에서 **Elements**로 이동한 다음 데이터가 담긴 테이블의 `HTML element`를 찾습니다. 타겟 `element`를 찾는 방법은 이제 잘 아시겠죠? 해당 위치로 가서 마우스 오른쪽 버튼을 클릭한 후 **검사(Inspect)**를 선택하면 그 주변에서 찾을 수 있습니다. 이 웹페이지는 `<table class="ltb-table responsive">`로 되어 있군요.

```{r}
# 원하는 태그가 있는지 확인합니다.
read_html(resp) %>% 
  html_nodes(css = "table.ltb-table")

# html_table() 함수를 이용하여 쉽게 정리하고 데이터프레임으로 변환합니다.
read_html(resp) %>% 
  html_nodes(css = "table.ltb-table") %>% 
  html_table() %>% 
  as.data.frame()
```

위와 같이 하면 아주 간단하게 원하는 데이터를 수집할 수 있습니다. 그런데 지금 우리는 겨우 20명의 타자 데이터만 수집하였습니다. 화면 맨 아래에 보면 페이지를 이동하는 네비게이션이 있습니다. 마지막 페이지로 이동해보니 모두 15개 페이지가 있음을 확인할 수 있었습니다.

페이지 이동은 어떻게 처리하면 좋을까요? 왠지 앞에서 `POST()` 함수의 `body` 인자를 설정할 때 `page = 1`로 되어 있던 기억이 납니다. 그럼 여기에서 `1` 대신에 `2`를 넣으면 2페이지가 되겠죠? 즉, `page`에 할당되는 값을 `1`부터 `15`까지 순환하며 데이터를 수집하면 됩니다.

같은 명령을 반복실행하려면 `for()` 함수를 사용하면 됩니다. 그리고 각 페이지별로 수집한 데이터를 데이터 프레임으로 만든 후 `rbind()` 함수를 이용하여 행 기준으로 추가하면 간단하게 해결됩니다.

순환함수 실행에 앞서 최종 결과 객체인 `hitterStat`을 빈 데이터 프레임으로 만들어 줍니다.

```{r}
# 최종 결과 객체를 먼저 생성합니다.
hitterStat <- data.frame()

# 총 15 페이지를 순환 실행하여 수집합니다.
for (i in 1:15) {
  resp <- POST(url = "http://www.kbreport.com/leader/list/ajax",
               encode = "form",
               body = list(
                 row = 20,
                 order = "oWAR",
                 orderType = "DESC",
                 year_from = 2017,
                 year_to = 2017,
                 gameType = "R",
                 page = i)
               )
  
  # 테이블에 있는 데이터를 데이터프레임에 할당합니다.
  df <- read_html(resp) %>% 
    html_nodes(css = "table.ltb-table") %>% 
    html_table() %>% 
    as.data.frame()
  
  # 새로 만든 데이터테이블을 결과 객체에 행 기준으로 추가합니다
  hitterStat <- rbind(hitterStat, df)
}
```

모든 데이터를 다 수집하였으니 이제 데이터 정제과정을 거치겠습니다. 거의 모든 데이터가 숫자 데이터이므로 번거로운 작업은 그렇게 많지 않을 것 같습니다.

```{r}
# 데이터 테이블 구조를 확인합니다.
str(hitterStat)
```

데이터 프레임 구조를 확인해보니 총 292명의 선수, 20개의 컬럼으로 구성되어 있습니다. 첫 번째 컬럼명이 현재 `X.`로 되어 있는데 이것을 `순위`로 변경해주는 것이 좋겠습니다.

```{r}
# 첫 번째 컬럼명을 "순위"로 변경합니다.
colnames(hitterStat)[1] <- "순위"
```

14~20 번째 컬럼이 문자 벡터로 되어 있습니다. 이 부분을 보정하기 위해 먼저 요약정보를 확인하고 필요한 조치를 취하도록 하겠습니다.

```{r}
# 14번째 컬럼 요약정보를 확인합니다.
table(hitterStat[14])
```

15번째 페이지에서 보여지는 것처럼 일부 선수들의 데이터가 `하이픈(-)`로 되어 있습니다. 이것 때문에 숫자가 아닌 문자 데이터로 강제전환된 것입니다. 이것을 제거하고 숫자 벡터로 변환하겠습니다.

```{r}
# 데이터 중 "-"를 제거합니다.
hitterStat[hitterStat == "-"] <- NA

# 14~20 번째 컬럼을 숫자 벡터로 변환합니다.
hitterStat[, 14:20] <- data.matrix(hitterStat[, 14:20])

# 데이터테이블 구조를 다시 확인합니다.
str(hitterStat)

# 처음 10행만 미리보기 합니다.
head(x = hitterStat, n = 10L)
```

이제까지 작업한 파일을 나중에 사용하기 위해 xlsx 파일로 저장하겠습니다. xlsx로 저장하려면 **xlsx** 패키지의 `write.xlsx()` 함수를 사용합니다.

```{r}
# 필요 패키지를 불러옵니다.
library(xlsx)

# 저장할 폴더를 지정합니다. 있는지 확인하고 없으면 새로 만듭니다.
newDir <- "./data"
if (dir.exists(paths = newDir) == FALSE) {
  dir.create(path = newDir)
}

# xlsx 파일로 저장합니다.
write.xlsx(x = hitterStat, 
           file = "./data/2017_Baseball_hitter_stat.xlsx",
           row.names = FALSE)
```

이상으로 **JavaScript**를 우회하여 웹데이터를 수집하는 방법에 대해 알아봤습니다. 다음 포스팅에서는 **RSelenium**을 이용하여 데이터를 수집하는 R Crawler 마지막 부분을 다루도록 하겠습니다.
