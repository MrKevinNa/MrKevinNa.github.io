<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>유사도의 척도, 거리의 종류</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>





<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h1>유사도의 척도, 거리의 종류</h1>

<p>Dr.Kevin
5/31/2018</p>

<p>일부 기계학습 알고리즘은 <strong>데이터 간 유사도 혹은 비유사도를 측정</strong>하는 경우가 있습니다. 유사도의 기준으로는 주로 <strong>거리(Distance)</strong>를 이용하는데요. 예를 들어 군집분석의 경우, 데이터 간 거리가 가까울수록 유사도가 높다고 판단하여 같은 군집으로 묶습니다. 지도학습의 K-근접이웃 역시 데이터 간 거리를 측정하고 가장 가까운 이웃들의 목표변수를 기준으로 새로운 데이터의 목표변수를 추론합니다.</p>

<h2>거리(Distance)의 특징</h2>

<p>함수 \[ d(x, y) \]를 두 점 x와 y의 거리는 반환하는 함수라고 가정했을 때, \[ d(x, y) \]는 다음과 같은 특징을 갖습니다.</p>

<ul>
<li><p>모든 거리는 0보다 크거나 같습니다.</p>

<p>\[ d(x, y) ≥ 0 \]</p></li>
<li><p>교환법칙이 성립합니다.</p>

<p>\[ d(x, y) = d(y, x) \]</p></li>
<li><p>다른 한 점 z를 경유하는 거리의 합보다 작거나 같습니다. (삼각 부등식)</p>

<p>\[ d(x, y) ≤ d(x, z) + d(y, z) \]</p></li>
</ul>

<h2>데이터 표준화와 정규화</h2>

<p>기계학습 알고리즘에서 거리 계산이 포함되는 경우, 반드시 데이터 전처리 과정에서 <strong>표준화 (Standardizatoin)</strong>를 해주어야 합니다. 표준화는 데이터 <code>x</code>를 평균이 0이고, 표준편차가 1인 표준정규분포를 따르는 <code>z-score</code>로 변환하는 것을 의미합니다.</p>

<p>\[ \text {z-score} = \frac {x - \mu}{\sigma} \]</p>

<p>R에서는 <code>scale()</code> 함수를 사용하여 손쉽게 표준화할 수 있습니다. <code>scale()</code> 함수의 주요 인자로는 <code>x</code>, <code>center</code>, <code>scale</code> 등 3가지가 있습니다.</p>

<ul>
<li>  <code>x</code> : 변환하려는 숫자형 벡터를 할당합니다.</li>
<li>  <code>center</code> : 위 식에서 분자의 \[ \mu \]에 해당하는 <code>x</code>의 평균을 할당합니다. 기본값으로 <code>TRUE</code>가 설정되어 있는데, 표준화 데이터의 평균을 0으로 할 때는 생략해도 무방합니다.</li>
<li>  <code>scale</code> : 위 식에서 분자의 \[ \sigma \]에 해당하는 <code>x</code>의 표준편차를 할당합니다. 기본값으로 <code>TRUE</code>가 설정되어 있는데, 표준화 데이터의 표준편차를 1로 할 때는 생략해도 무방합니다.</li>
</ul>

<p>그런데 표준화 대신 정규화를 하는 경우가 있으니 참고로 소개해드리겠습니다. 정규화는 데이터 <code>x</code>를 0~1 사이의 값을 갖도록 변환하는 것입니다. 위 식에서 분자의 \[ \mu \] 대신 <code>최소값</code>을 넣고, 분모의 \[ \sigma \] 대신 <code>(최대값 - 최소값)</code>을 넣으면 됩니다.</p>

<p>\[ \text {x-normalized} = \frac {x - \text{min}}{\text {max - min}} \]</p>

<p>정규화 역시 <code>scale()</code> 함수를 이용하면 되며, 표준화와 달리 <code>center</code>, <code>scale</code> 인자에 반드시 해당하는 데이터를 할당해주어야 합니다.</p>

<ul>
<li>  <code>center</code> : <code>min(x)</code>를 할당합니다.</li>
<li>  <code>scale</code> : (<code>max(x)</code> - <code>min(x)</code>)를 할당합니다.</li>
</ul>

<h2>거리의 종류</h2>

<p>p차원의 공간에 두 점 \[ A(x_1, x_2, \cdots, x_p) \]와 \[ B(y_1, y_2, \cdots, y_p) \]가 있다고 할 때, 두 점 사이의 거리는 종류에 따라 다음과 같이 계산할 수 있습니다.</p>

<ul>
<li><p>맨하탄 거리 : 두 점 간 차의 절대값을 합한 값으로 \[ \text {L}_1 \] norm이라고 합니다. 격자 모양의 거리를 자동차로 운행하는 거리를 연상하면 됩니다. <strong>택시거리</strong>라는 별칭을 가지고 있습니다.</p>

<p>\[ d(A, B) = \| x_i - y_i \|_1 = \sum_{i=1}^{p} | x_i - y_i | \]</p></li>
<li><p>유클리드 거리 : 두 점 간 차를 제곱하여 모두 더한 값의 양의 제곱근으로 \[ \text {L}_2 \] norm이라고 합니다.</p>

<p>\[ d(A, B) = \| x_i - y_i \|_2 = \sqrt [2] {\sum_{i=1}^{p} (x_i - y_i)^2} = \biggl[ \sum_{i=1}^{p} (x_i - y_i)^2 \biggl]^{\frac {1}{2}} \]</p></li>
<li><p>민코프스키 거리 : m차원 민코프스키 공간에서의 거리입니다. m=1일 때 맨하탄 거리와 같고, m=2일 때 유클리드 거리와 같습니다. m이 정수가 아니어도 되지만 반드시 1보다 커야 합니다.</p>

<p>\[ d(A, B) = \sqrt [m] {\sum_{i=1}^{p} (x_i - y_i)^m} = \biggl[ \sum_{i=1}^{p} (x_i - y_i)^m \biggl]^{\frac {1}{m}} \]</p></li>
<li><p>맥시멈 거리 : 민코프스키 거리에서 m을 무한대로 확장한 거리입니다. 체비셰프(Chebyshev) 거리라고도 하며, 두 집단에서 가장 긴 지점에서의 거리를 의미합니다.</p>

<p>\[ d(A, B) = \lim_{m \to \infty} \biggl[ \sum_{i=1}^{p} (x_i - y_i)^m \biggl]^{\frac {1}{m}} = \max \biggl( {| x_1 - y_1 |}, \; {| x_2 - y_2 |}, \; \cdots \; , \; {| x_p - y_p |} \biggl) \]</p></li>
<li><p>표준화 거리 : 유클리드 거리를 공분산으로 나눈 거리입니다. 공분산을 원소로 갖는 대각행렬(\[ D \])을 이용합니다.</p>

<p>\[ d(A, B) = \biggl[ \sum_{i=1}^{p} \frac {(x_i - y_i)^2}{\sigma_{ii}} \biggl]^{\frac {1}{2}} = \biggl[ (X - Y)^T D^{-1} (X - Y) \biggl]^{\frac{1}{2}} \]</p>

<p>\[ D = \left[ \begin{array}{ccc} \sigma_{11} & 0 & \cdots & 0 \\ 0 & \sigma_{22} & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & \sigma_{pp} \\ \end{array} \right] \]</p></li>
<li><p>캔버라 거리 : 가중치 있는 맨하탄 거리입니다. 원점 주변에 흩어져 있는 데이터에 주로 사용됩니다.</p>

<p>\[ \text {d(A, B)} = \sum_{i=1}^{p} \frac { | x_i - y_i | } { | x_i |  +  | y_i | } \]</p></li>
<li><p>마할라노비스 거리 : 확률분포를 고려해야 할 때, 공분산 행렬(\[ \Sigma^{-1} \])을 이용합니다.</p>

<p>\[ \text {d(A, B)} = \biggl[ (X - Y)^T \Sigma^{-1} (X - Y) \biggl]^{\frac {1}{2}} \]</p>

<p>\[ \Sigma = \left[ \begin{array}{ccc} \sigma_{11} & \sigma_{12} & \cdots & \sigma_{1p} \\ \sigma_{21} & \sigma_{22} & \cdots & \sigma_{2p} \\ \vdots & \vdots & \ddots & \vdots \\ \sigma_{p1} & \sigma_{p2} & \cdots & \sigma_{pp} \\ \end{array} \right] \]</p></li>
<li><p>코사인 유사도 : 두 벡터이 내적을 각 벡터의 크기로 나눈 값을 1에서 뺀 것입니다. 코사인은 0 ~ 1 사이의 값을 갖는데, 0도 일 때 1, 90도일 때 0의 값을 갖는다는 점을 착안한다면 두 벡터의 사이각이 0에 가까울수록 두 벡터의 거리가 가깝다고 판단할 수 있습니다.</p>

<p>\[ d(A, B) = 1 - \frac { \langle x, \; y \rangle} {\| x \|_2 \|y\|_2} = 1 - \frac {\sum_{i=1}^{p} x_i y_i}{\sqrt [2] {\sum_{i=1}^{p} x_i^2} \sqrt [2] {\sum_{i=1}^{p} y_i^2} } \]</p></li>
<li><p>피어슨 거리 : 피어슨 상관계수가 -1 ~ 1 사이의 값을 가지므로, 피어슨 상관계수를 1에서 뺀 값은 0 ~ 2 사이의 값을 갖게 됩니다.</p>

<p>\[ d(A, B) = 1 − \text {Corr} (x, y) \]</p></li>
</ul>

<p>이상으로 기계학습에서 유사도의 기준으로 삼는 거리의 특징과 종류를 알아봤습니다.</p>

</body>

</html>
